{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d41f435a",
   "metadata": {},
   "source": [
    "# 可微量子架构搜索"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50b478cb",
   "metadata": {},
   "source": [
    "## 概述\n",
    "\n",
    "本教程演示了如何利用 TensorCircuit 提供的高级计算功能，例如 ``jit`` 和 ``vmap`` 来超级有效地模拟可微量子架构搜索（DQAS）算法，其中具有不同结构的量子电路的集合可以同时编译模拟。\n",
    "[WIP note]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0704d1f4",
   "metadata": {},
   "source": [
    "## 设置"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b523ddaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorcircuit as tc\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b35c5c59",
   "metadata": {},
   "outputs": [],
   "source": [
    "K = tc.set_backend(\"tensorflow\")\n",
    "ctype, rtype = tc.set_dtype(\"complex128\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff3654c0",
   "metadata": {},
   "source": [
    "## 问题描述\n",
    "\n",
    "任务是找到 GHZ 状态的状态准备电路 $\\vert \\text{GHZ}_N\\rangle = \\frac{1}{\\sqrt{2}}\\left(\\vert 0^N\\rangle +\\vert 1^N\\rangle \\right)$。我们为 $N=2$ 演示准备了一个包含 rx0、rx1、ry0、ry1、rz0、rz1、cnot01、cnot10 的门池。 在八个门中，有六个是参数化的。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9731c922",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rx0(theta):\n",
    "    return K.kron(\n",
    "        K.cos(theta) * K.eye(2) + 1.0j * K.sin(theta) * tc.gates._x_matrix, K.eye(2)\n",
    "    )\n",
    "\n",
    "\n",
    "def rx1(theta):\n",
    "    return K.kron(\n",
    "        K.eye(2), K.cos(theta) * K.eye(2) + 1.0j * K.sin(theta) * tc.gates._x_matrix\n",
    "    )\n",
    "\n",
    "\n",
    "def ry0(theta):\n",
    "    return K.kron(\n",
    "        K.cos(theta) * K.eye(2) + 1.0j * K.sin(theta) * tc.gates._y_matrix, K.eye(2)\n",
    "    )\n",
    "\n",
    "\n",
    "def ry1(theta):\n",
    "    return K.kron(\n",
    "        K.eye(2), K.cos(theta) * K.eye(2) + 1.0j * K.sin(theta) * tc.gates._y_matrix\n",
    "    )\n",
    "\n",
    "\n",
    "def rz0(theta):\n",
    "    return K.kron(\n",
    "        K.cos(theta) * K.eye(2) + 1.0j * K.sin(theta) * tc.gates._z_matrix, K.eye(2)\n",
    "    )\n",
    "\n",
    "\n",
    "def rz1(theta):\n",
    "    return K.kron(\n",
    "        K.eye(2), K.cos(theta) * K.eye(2) + 1.0j * K.sin(theta) * tc.gates._z_matrix\n",
    "    )\n",
    "\n",
    "\n",
    "def cnot01():\n",
    "    return K.cast(K.convert_to_tensor(tc.gates._cnot_matrix), ctype)\n",
    "\n",
    "\n",
    "def cnot10():\n",
    "    return K.cast(\n",
    "        K.convert_to_tensor(\n",
    "            np.array([[0, 1, 0, 0], [1, 0, 0, 0], [0, 0, 1, 0], [0, 0, 0, 1]])\n",
    "        ),\n",
    "        ctype,\n",
    "    )\n",
    "\n",
    "\n",
    "ops_repr = [\"rx0\", \"rx1\", \"ry0\", \"ry1\", \"rz0\", \"rz1\", \"cnot01\", \"cnot10\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "be9e5e07",
   "metadata": {},
   "outputs": [],
   "source": [
    "n, p, ch = 2, 3, 8\n",
    "# 量子比特数、层数、操作池大小\n",
    "\n",
    "target = tc.array_to_tensor(np.array([1, 0, 0, 1.0]) / np.sqrt(2.0))\n",
    "# 目标波函数，我们这里使用 GHZ2 状态作为目标函数\n",
    "\n",
    "\n",
    "def ansatz(params, structures):\n",
    "    c = tc.Circuit(n)\n",
    "    params = K.cast(params, ctype)\n",
    "    structures = K.cast(structures, ctype)\n",
    "    for i in range(p):\n",
    "        c.any(\n",
    "            0,\n",
    "            1,\n",
    "            unitary=structures[i, 0] * rx0(params[i, 0])\n",
    "            + structures[i, 1] * rx1(params[i, 1])\n",
    "            + structures[i, 2] * ry0(params[i, 2])\n",
    "            + structures[i, 3] * ry1(params[i, 3])\n",
    "            + structures[i, 4] * rz0(params[i, 4])\n",
    "            + structures[i, 5] * rz1(params[i, 5])\n",
    "            + structures[i, 6] * cnot01()\n",
    "            + structures[i, 7] * cnot10(),\n",
    "        )\n",
    "    s = c.state()\n",
    "    loss = K.sum(K.abs(target - s))\n",
    "    return loss\n",
    "\n",
    "\n",
    "vag1 = K.jit(K.vvag(ansatz, argnums=0, vectorized_argnums=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "751beb4d",
   "metadata": {},
   "source": [
    "## 概率系综方法\n",
    "\n",
    "这种方法更加实用和实验相关，并且与参考文献 1 中描述的算法相同，尽管我们在这里使用高级 vmap 来加速具有不同结构的电路的仿真。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c71c5552",
   "metadata": {},
   "outputs": [],
   "source": [
    "structures = K.zeros([p, ch], rtype)\n",
    "\n",
    "\n",
    "def sampling_from_structure(structures, batch=1):\n",
    "    prob = K.softmax(K.real(structures), axis=-1)\n",
    "    return np.array([np.random.choice(ch, p=K.numpy(prob[i])) for i in range(p)])\n",
    "\n",
    "\n",
    "@K.jit\n",
    "def best_from_structure(structures):\n",
    "    return K.argmax(structures, axis=-1)\n",
    "\n",
    "\n",
    "@K.jit\n",
    "def nmf_gradient(structures, oh):\n",
    "    \"\"\"\n",
    "    根据朴素平均场概率模型计算蒙特卡洛梯度\n",
    "    \"\"\"\n",
    "    choice = K.argmax(oh, axis=-1)\n",
    "    prob = K.softmax(K.real(structures), axis=-1)\n",
    "    indices = K.transpose(K.stack([K.cast(tf.range(p), \"int64\"), choice]))\n",
    "    prob = tf.gather_nd(prob, indices)\n",
    "    prob = K.reshape(prob, [-1, 1])\n",
    "    prob = K.tile(prob, [1, ch])\n",
    "\n",
    "    return tf.tensor_scatter_nd_add(\n",
    "        tf.cast(-prob, dtype=ctype),\n",
    "        indices,\n",
    "        tf.ones([p], dtype=ctype),\n",
    "    )\n",
    "\n",
    "\n",
    "nmf_gradient_vmap = K.vmap(nmf_gradient, vectorized_argnums=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e9072ce1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting GatherNd\n",
      "WARNING:tensorflow:Using a while_loop for converting TensorScatterAdd\n",
      "----------epoch 0-----------\n",
      "batched average loss:  1.4212375301510944\n",
      "best candidates so far: ['cnot01', 'ry1', 'rz1']\n",
      "corresponding weights for each gate: [0.0, 0.05877275111731101, -0.04664915789120658]\n",
      "----------epoch 40-----------\n",
      "batched average loss:  1.0250998670008267\n",
      "best candidates so far: ['cnot01', 'rz0', 'cnot01']\n",
      "corresponding weights for each gate: [0.0, 0.024759131232497896, 0.0]\n",
      "----------epoch 80-----------\n",
      "batched average loss:  0.8947977316164302\n",
      "best candidates so far: ['cnot01', 'rz0', 'cnot01']\n",
      "corresponding weights for each gate: [0.0, 0.025322026393257882, 0.0]\n",
      "----------epoch 120-----------\n",
      "batched average loss:  0.03468271497984207\n",
      "best candidates so far: ['cnot01', 'ry0', 'cnot01']\n",
      "corresponding weights for each gate: [0.0, -0.7656295586663117, 0.0]\n",
      "----------epoch 160-----------\n",
      "batched average loss:  0.012709563347046916\n",
      "best candidates so far: ['cnot01', 'ry0', 'cnot01']\n",
      "corresponding weights for each gate: [0.0, -0.7675056347152348, 0.0]\n",
      "----------epoch 200-----------\n",
      "batched average loss:  0.006081581476382821\n",
      "best candidates so far: ['cnot01', 'ry0', 'cnot01']\n",
      "corresponding weights for each gate: [0.0, -0.7694529377688849, 0.0]\n",
      "----------epoch 240-----------\n",
      "batched average loss:  0.0035806003462887535\n",
      "best candidates so far: ['cnot01', 'ry0', 'cnot01']\n",
      "corresponding weights for each gate: [0.0, -0.771253402671928, 0.0]\n",
      "----------epoch 280-----------\n",
      "batched average loss:  0.0015910659581530712\n",
      "best candidates so far: ['cnot01', 'ry0', 'cnot01']\n",
      "corresponding weights for each gate: [0.0, -0.7728266168903171, 0.0]\n",
      "----------epoch 320-----------\n",
      "batched average loss:  0.007875267706110904\n",
      "best candidates so far: ['cnot01', 'ry0', 'cnot01']\n",
      "corresponding weights for each gate: [0.0, -0.7961765599630959, 0.0]\n",
      "----------epoch 360-----------\n",
      "batched average loss:  5.3187907396145856e-05\n",
      "best candidates so far: ['cnot01', 'ry0', 'cnot01']\n",
      "corresponding weights for each gate: [0.0, -0.7939760130910373, 0.0]\n",
      "----------epoch 399-----------\n",
      "batched average loss:  0.009744394329971349\n",
      "best candidates so far: ['cnot01', 'ry0', 'cnot01']\n",
      "corresponding weights for each gate: [0.0, -0.7853654549996214, 0.0]\n"
     ]
    }
   ],
   "source": [
    "verbose = False\n",
    "epochs = 400\n",
    "batch = 256\n",
    "lr = tf.keras.optimizers.schedules.ExponentialDecay(0.06, 100, 0.5)\n",
    "structure_opt = tc.backend.optimizer(tf.keras.optimizers.Adam(0.12))\n",
    "network_opt = tc.backend.optimizer(tf.keras.optimizers.Adam(lr))\n",
    "nnp = K.implicit_randn(stddev=0.02, shape=[p, 6], dtype=rtype)\n",
    "stp = K.implicit_randn(stddev=0.02, shape=[p, 8], dtype=rtype)\n",
    "avcost1 = 0\n",
    "for epoch in range(epochs):  # 更新结构参数的迭代\n",
    "    avcost2 = avcost1\n",
    "    costl = []\n",
    "    batched_stuctures = K.onehot(\n",
    "        np.stack([sampling_from_structure(stp) for _ in range(batch)]), num=8\n",
    "    )\n",
    "    infd, gnnp = vag1(nnp, batched_stuctures)\n",
    "    gs = nmf_gradient_vmap(structures, batched_stuctures)  # \\nabla lnp\n",
    "    gstp = [K.cast((infd[i] - avcost2), ctype) * gs[i] for i in range(infd.shape[0])]\n",
    "    gstp = K.real(K.sum(gstp, axis=0) / infd.shape[0])\n",
    "    avcost1 = K.sum(infd) / infd.shape[0]\n",
    "    nnp = network_opt.update(gnnp, nnp)\n",
    "    stp = structure_opt.update(gstp, stp)\n",
    "\n",
    "    if epoch % 40 == 0 or epoch == epochs - 1:\n",
    "        print(\"----------epoch %s-----------\" % epoch)\n",
    "        print(\n",
    "            \"batched average loss: \",\n",
    "            np.mean(avcost1),\n",
    "        )\n",
    "\n",
    "        if verbose:\n",
    "            print(\n",
    "                \"strcuture parameter: \\n\",\n",
    "                stp.numpy(),\n",
    "                \"\\n network parameter: \\n\",\n",
    "                nnp.numpy(),\n",
    "            )\n",
    "\n",
    "        cand_preset = best_from_structure(stp)\n",
    "        print(\"best candidates so far:\", [ops_repr[i] for i in cand_preset])\n",
    "        print(\n",
    "            \"corresponding weights for each gate:\",\n",
    "            [K.numpy(nnp[j, i]) if i < 6 else 0.0 for j, i in enumerate(cand_preset)],\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e2824b3",
   "metadata": {},
   "source": [
    "## 直接优化结构参数\n",
    "\n",
    "无论如何，由于我们是用数值模拟，所以可以直接优化结构参数，省略超级电路是否是幺正的，这种方法在某些场景下可以更快更可靠。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e709fb2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ansatz2(params, structures):\n",
    "    c = tc.Circuit(n)\n",
    "    params = K.cast(params, ctype)\n",
    "    structures = K.softmax(structures, axis=-1)\n",
    "    structures = K.cast(structures, ctype)\n",
    "    for i in range(p):\n",
    "        c.any(\n",
    "            0,\n",
    "            1,\n",
    "            unitary=structures[i, 0] * rx0(params[i, 0])\n",
    "            + structures[i, 1] * rx1(params[i, 1])\n",
    "            + structures[i, 2] * ry0(params[i, 2])\n",
    "            + structures[i, 3] * ry1(params[i, 3])\n",
    "            + structures[i, 4] * rz0(params[i, 4])\n",
    "            + structures[i, 5] * rz1(params[i, 5])\n",
    "            + structures[i, 6] * cnot01()\n",
    "            + structures[i, 7] * cnot10(),\n",
    "        )\n",
    "    s = c.state()\n",
    "    s /= K.norm(s)\n",
    "    loss = K.sum(K.abs(target - s))\n",
    "    return loss\n",
    "\n",
    "\n",
    "vag2 = K.jit(K.value_and_grad(ansatz2, argnums=(0, 1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "69258140",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------epoch 0-----------\n",
      "batched average loss:  1.3024341605187928\n",
      "strcuture parameter: \n",
      " [[ 0.00265054  0.04495954  0.05265605  0.04751008  0.03309468  0.02743368\n",
      "   0.03382795 -0.06647121]\n",
      " [ 0.03544281  0.03207712  0.03629811  0.0266235   0.03264895  0.03198189\n",
      "   0.03505167 -0.03449981]\n",
      " [ 0.0304648   0.07042194  0.03075206  0.02515865  0.02984363  0.00955019\n",
      "   0.07527341 -0.05831911]] \n",
      " network parameter: \n",
      " [[-0.0380125   0.0688923   0.04393423  0.04205065  0.06243917  0.03672062]\n",
      " [-0.05277717  0.04834309  0.05176114  0.07030034  0.02983666  0.04821408]\n",
      " [-0.04095011  0.0393773   0.03383929  0.06559557  0.03458135  0.02436751]]\n",
      "best candidates so far: ['ry0', 'ry0', 'cnot01']\n",
      "corresponding weights for each gate: [0.043934227235354874, 0.05176113831452516, 0.0]\n",
      "----------epoch 70-----------\n",
      "batched average loss:  1.0078726220234666\n",
      "strcuture parameter: \n",
      " [[ 0.34119556  0.37154559  0.2781548   0.37689646  1.79624262  1.78939153\n",
      "   1.79791154 -0.3958881 ]\n",
      " [-1.04375011 -0.1280161  -0.98656309  0.35601588  1.79624062  1.7944131\n",
      "   1.80069633 -0.36391841]\n",
      " [ 0.05278476  0.40486479  0.33074328  0.35455104  1.79289574  1.77260117\n",
      "   1.83987217 -0.38773815]] \n",
      " network parameter: \n",
      " [[ 0.03213363 -0.00113532 -0.02629044  0.44615806 -0.00711866 -0.03271277]\n",
      " [ 0.01737624 -0.02169861 -0.01841347  0.47440825  0.01052075 -0.02137655]\n",
      " [ 0.02919352 -0.03064528 -0.03628025  0.46970421 -0.03434029 -0.04519493]]\n",
      "best candidates so far: ['cnot01', 'cnot01', 'cnot01']\n",
      "corresponding weights for each gate: [0.0, 0.0, 0.0]\n",
      "----------epoch 140-----------\n",
      "batched average loss:  0.8974790925982725\n",
      "strcuture parameter: \n",
      " [[-0.60734424 -0.71178177  1.75016478  0.37059946  2.29304101  1.40087053\n",
      "   2.75041722 -0.4812161 ]\n",
      " [-3.20848853 -2.62803529 -1.0799243   0.34964202  1.75222537  0.96340588\n",
      "   4.59441388 -0.44922864]\n",
      " [-1.14052853 -0.10976557  0.9998582   0.34848638  3.81458301  3.38821681\n",
      "   2.51193413 -0.38172792]] \n",
      " network parameter: \n",
      " [[-0.03052873 -0.00288839 -1.08840853  0.51536679 -0.00833568 -0.03375284]\n",
      " [ 0.0216315  -0.02917968  0.8216509   0.54353084  0.00946658 -0.02120069]\n",
      " [ 0.02581133 -0.03281417  0.94900358  0.46842014 -0.0355813  -0.04637678]]\n",
      "best candidates so far: ['cnot01', 'cnot01', 'rz0']\n",
      "corresponding weights for each gate: [0.0, 0.0, -0.03558129647764995]\n",
      "----------epoch 210-----------\n",
      "batched average loss:  0.06833171337421318\n",
      "strcuture parameter: \n",
      " [[-1.46101866 -1.56562139  2.60460926  0.36697705  1.43861808  0.54649088\n",
      "   1.8959831  -0.6664916 ]\n",
      " [-2.8599476  -3.71447893 -0.1444609  -0.31801788  0.70398108  0.12590137\n",
      "   5.44896172 -0.64032593]\n",
      " [-0.29063004  0.46966802  1.85427644  0.44130728  4.56540152  4.13933904\n",
      "   1.26524942 -0.47396024]] \n",
      " network parameter: \n",
      " [[-0.80254223 -0.07223631 -1.72113169  0.65719836 -0.00717114 -0.03248183]\n",
      " [ 0.86880067 -0.98161163  1.73279897  0.68543186  0.57173565  0.81901641]\n",
      " [ 0.41384514  0.03460214  1.4409846   0.26020133 -0.03450978 -0.04528429]]\n",
      "best candidates so far: ['ry0', 'cnot01', 'rz0']\n",
      "corresponding weights for each gate: [-1.7211316854515077, 0.0, -0.03450978363305436]\n",
      "----------epoch 280-----------\n",
      "batched average loss:  0.07287093721912785\n",
      "strcuture parameter: \n",
      " [[-1.46462962 -1.5694426   2.60832482  0.36325644  1.43489835  0.54276147\n",
      "   1.89226573 -0.66280103]\n",
      " [-1.57089047 -3.66510778 -0.14837051 -0.32242832  0.70013882  0.1239224\n",
      "   5.45278654 -0.63670874]\n",
      " [-0.28665073  0.50527464  1.85793113  0.43721505  4.56217177  4.13630294\n",
      "   1.26107282 -0.47016776]] \n",
      " network parameter: \n",
      " [[-0.80172748 -0.0712512  -1.71930255  0.6591615  -0.00531003 -0.030584  ]\n",
      " [ 0.8833277  -1.26937984  1.73185803  0.68715766  0.57394473  0.8184381 ]\n",
      " [ 0.41194181  0.03270603  1.4387577   0.26174242 -0.03266689 -0.04343292]]\n",
      "best candidates so far: ['ry0', 'cnot01', 'rz0']\n",
      "corresponding weights for each gate: [-1.7193025540909423, 0.0, -0.032666892917796356]\n",
      "----------epoch 350-----------\n",
      "batched average loss:  0.0763633455796077\n",
      "strcuture parameter: \n",
      " [[-1.46759968 -1.57262214  2.61142979  0.36014718  1.43179046  0.53964649\n",
      "   1.88915951 -0.65972411]\n",
      " [-1.34936013 -3.5935837  -0.15090151 -0.32639326  0.69677033  0.10483803\n",
      "   5.45606073 -0.63438681]\n",
      " [-0.28282805  0.54032205  1.86109945  0.43217854  4.55947529  4.13345958\n",
      "   1.25730198 -0.46703484]] \n",
      " network parameter: \n",
      " [[-0.80018367 -0.06928467 -1.71726239  0.66128651 -0.00323225 -0.0284642 ]\n",
      " [ 0.88958794 -1.36344637  1.73074888  0.68928184  0.57647947  0.81753049]\n",
      " [ 0.40992401  0.03064141  1.43664452  0.26328958 -0.03061012 -0.04136483]]\n",
      "best candidates so far: ['ry0', 'cnot01', 'rz0']\n",
      "corresponding weights for each gate: [-1.7172623928298167, 0.0, -0.030610123400026196]\n",
      "----------epoch 420-----------\n",
      "batched average loss:  0.07933778661926846\n",
      "strcuture parameter: \n",
      " [[-1.47009725 -1.57533451  2.61409128  0.35748195  1.42912701  0.53697792\n",
      "   1.88649718 -0.65709335]\n",
      " [-1.19469005 -3.49291914 -0.15236124 -0.32995762  0.69380539  0.07513886\n",
      "   5.45890732 -0.63296266]\n",
      " [-0.27952556  0.57900165  1.86385667  0.42698093  4.55720421  4.13093395\n",
      "   1.25401354 -0.46439162]] \n",
      " network parameter: \n",
      " [[-7.98493487e-01 -6.71330183e-02 -1.71528444e+00  6.63308869e-01\n",
      "  -1.20663132e-03 -2.63889444e-02]\n",
      " [ 8.92122476e-01 -1.41065660e+00  1.72949508e+00  6.91390756e-01\n",
      "   5.79085213e-01  8.16347571e-01]\n",
      " [ 4.07963360e-01  2.86428770e-02  1.43467895e+00  2.64831277e-01\n",
      "  -2.86101270e-02 -3.93481586e-02]]\n",
      "best candidates so far: ['ry0', 'cnot01', 'rz0']\n",
      "corresponding weights for each gate: [-1.7152844386878365, 0.0, -0.028610127013962768]\n",
      "----------epoch 490-----------\n",
      "batched average loss:  0.08254545024351018\n",
      "strcuture parameter: \n",
      " [[-1.47222071e+00 -1.57769163e+00  2.61641114e+00  3.55158679e-01\n",
      "   1.42680584e+00  5.34652980e-01  1.88417675e+00 -6.54806876e-01]\n",
      " [-9.73250463e-01 -3.16903830e+00 -3.18559749e-03 -3.33158739e-01\n",
      "   8.55776706e-01  5.24787309e-02  5.46137377e+00 -4.79944986e-01]\n",
      " [-4.31555592e-01  6.29503046e-01  1.86558679e+00  4.22659216e-01\n",
      "   4.55614569e+00  4.13032405e+00  1.25003608e+00 -4.62133108e-01]] \n",
      " network parameter: \n",
      " [[-7.96868537e-01 -6.41205534e-02 -1.71348758e+00  6.65124861e-01\n",
      "   7.01296452e-04 -2.44123401e-02]\n",
      " [ 8.95067083e-01 -1.46634629e+00  1.72823707e+00  6.93124762e-01\n",
      "   6.19045003e-01  8.16911575e-01]\n",
      " [ 3.68577179e-01 -1.06859075e-02  1.43203849e+00  2.65575517e-01\n",
      "  -2.67782067e-02 -3.74965029e-02]]\n",
      "best candidates so far: ['ry0', 'cnot01', 'rz0']\n",
      "corresponding weights for each gate: [-1.7134875797200289, 0.0, -0.026778206681234634]\n",
      "----------epoch 560-----------\n",
      "batched average loss:  0.08507962845391319\n",
      "strcuture parameter: \n",
      " [[-1.47404605e+00 -1.57976616e+00  2.61845726e+00  3.53109374e-01\n",
      "   1.42475889e+00  5.32603322e-01  1.88213024e+00 -6.52796788e-01]\n",
      " [-9.74391719e-01 -2.60249357e+00 -5.45311032e-03 -3.36090881e-01\n",
      "   8.87457853e-01  5.09795396e-02  5.46352386e+00 -4.77818480e-01]\n",
      " [-4.31981604e-01  7.01277774e-01  1.86614168e+00  4.17460986e-01\n",
      "   4.55685554e+00  4.13219105e+00  1.24506389e+00 -4.60189080e-01]] \n",
      " network parameter: \n",
      " [[-0.7953961  -0.05746862 -1.7119146   0.66669705  0.00291374 -0.0224405 ]\n",
      " [ 0.90083188 -1.50990732  1.72710663  0.69459133  0.61788545  0.82003669]\n",
      " [ 0.37017675 -0.00904591  1.42870116  0.26514657 -0.02513608 -0.03583994]]\n",
      "best candidates so far: ['ry0', 'cnot01', 'rz0']\n",
      "corresponding weights for each gate: [-1.711914597657612, 0.0, -0.025136080292754256]\n",
      "----------epoch 630-----------\n",
      "batched average loss:  0.0874301658835076\n",
      "strcuture parameter: \n",
      " [[-1.47562848 -1.58159874  2.62027778  0.35128611  1.42293816  0.53078116\n",
      "   1.88030961 -0.65101441]\n",
      " [-0.97538969 -2.02211517 -0.00750621 -0.33876198  0.90002101  0.04975063\n",
      "   5.46545544 -0.47588949]\n",
      " [-0.43177273  0.78495553  1.86618092  0.41182654  4.55815983  4.13468705\n",
      "   1.24131582 -0.45851101]] \n",
      " network parameter: \n",
      " [[-0.79411737 -0.03262083 -1.71056973  0.66801607  0.00931137 -0.02061058]\n",
      " [ 0.90559687 -1.52299082  1.72605402  0.69584073  0.61673658  0.82270295]\n",
      " [ 0.37157164 -0.00763778  1.42576784  0.26501218 -0.02367246 -0.03437195]]\n",
      "best candidates so far: ['ry0', 'cnot01', 'rz0']\n",
      "corresponding weights for each gate: [-1.7105697331825656, 0.0, -0.02367245788118412]\n",
      "----------epoch 699-----------\n",
      "batched average loss:  0.07954282768319362\n",
      "strcuture parameter: \n",
      " [[-1.38724436 -1.4934299   2.53210121  0.43945868  1.51111454  0.61895662\n",
      "   1.96848611 -0.7392194 ]\n",
      " [-0.88692788 -1.19022046  0.08057521 -0.25156948  0.81347111 -0.04509805\n",
      "   5.3775582  -0.56406862]\n",
      " [-0.34354263  0.94817808  1.77696399  0.48982178  4.64871759  4.22638916\n",
      "   1.32761078 -0.54681732]] \n",
      " network parameter: \n",
      " [[-0.78310707  0.01573153 -1.69951606  0.67901289  0.0447718  -0.00935101]\n",
      " [ 0.91920164 -1.51646333  1.7152693   0.70682227  0.60494688  0.8352184 ]\n",
      " [ 0.38342071  0.00423554  1.41389299  0.27478806 -0.01255172 -0.02324825]]\n",
      "best candidates so far: ['ry0', 'cnot01', 'rz0']\n",
      "corresponding weights for each gate: [-1.6995160647885235, 0.0, -0.01255171733214709]\n"
     ]
    }
   ],
   "source": [
    "verbose = True\n",
    "epochs = 700\n",
    "lr = tf.keras.optimizers.schedules.ExponentialDecay(0.05, 200, 0.5)\n",
    "structure_opt = tc.backend.optimizer(tf.keras.optimizers.Adam(0.04))\n",
    "network_opt = tc.backend.optimizer(tf.keras.optimizers.Adam(lr))\n",
    "nnp = K.implicit_randn(stddev=0.02, shape=[p, 6], dtype=rtype)\n",
    "stp = K.implicit_randn(stddev=0.02, shape=[p, 8], dtype=rtype)\n",
    "for epoch in range(epochs):\n",
    "\n",
    "    infd, (gnnp, gstp) = vag2(nnp, stp)\n",
    "\n",
    "    nnp = network_opt.update(gnnp, nnp)\n",
    "    stp = structure_opt.update(gstp, stp)\n",
    "    if epoch % 70 == 0 or epoch == epochs - 1:\n",
    "        print(\"----------epoch %s-----------\" % epoch)\n",
    "        print(\n",
    "            \"batched average loss: \",\n",
    "            np.mean(infd),\n",
    "        )\n",
    "        if verbose:\n",
    "            print(\n",
    "                \"strcuture parameter: \\n\",\n",
    "                stp.numpy(),\n",
    "                \"\\n network parameter: \\n\",\n",
    "                nnp.numpy(),\n",
    "            )\n",
    "\n",
    "        cand_preset = best_from_structure(stp)\n",
    "        print(\"best candidates so far:\", [ops_repr[i] for i in cand_preset])\n",
    "        print(\n",
    "            \"corresponding weights for each gate:\",\n",
    "            [K.numpy(nnp[j, i]) if i < 6 else 0.0 for j, i in enumerate(cand_preset)],\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fc3d1df",
   "metadata": {},
   "source": [
    "## 最后的微调\n",
    "\n",
    "对于获得的电路布局，我们可以进一步调整电路权重，使目标函数更接近于零。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "486aa70d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 3, 8), dtype=float32, numpy=\n",
       "array([[[0., 0., 1., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 1., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 1., 0.]]], dtype=float32)>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chosen_structure = K.onehot(np.array([2, 4, 6]), num=8)\n",
    "chosen_structure = K.reshape(chosen_structure, [1, p, ch])\n",
    "chosen_structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7d003077",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 loss:  1.004872758871745\n",
      "60 loss:  0.9679200431227549\n",
      "120 loss:  0.9091748060127385\n",
      "180 loss:  0.8302632245154631\n",
      "240 loss:  0.73297561645977\n",
      "300 loss:  0.6183436622858383\n",
      "360 loss:  0.4874390992051161\n",
      "420 loss:  0.34168453047914643\n",
      "480 loss:  0.18299822849737177\n",
      "540 loss:  0.013923344772669728\n",
      "599 loss:  0.0016133833518836463\n"
     ]
    }
   ],
   "source": [
    "network_opt = tc.backend.optimizer(tf.keras.optimizers.Adam(1e-3))\n",
    "nnp = K.implicit_randn(stddev=0.02, shape=[p, 6], dtype=rtype)\n",
    "verbose = True\n",
    "epochs = 600\n",
    "for epoch in range(epochs):\n",
    "    infd, gnnp = vag1(nnp, chosen_structure)\n",
    "    nnp = network_opt.update(gnnp, nnp)\n",
    "    if epoch % 60 == 0 or epoch == epochs - 1:\n",
    "        print(epoch, \"loss: \", K.numpy(infd[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58b1ddc3",
   "metadata": {},
   "source": [
    "## 参考资料\n",
    "\n",
    "1. https://arxiv.org/pdf/2010.08561.pdf"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
