{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "88fcd9ea",
   "metadata": {},
   "source": [
    "# Quantum Machine Learning for Classification Task\n",
    "\n",
    "**Demonstrations on some common setups and techniques**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abcb3f1b",
   "metadata": {},
   "source": [
    "## Overview\n",
    "\n",
    "We use the fashion-MNIST dataset to set up a binary classification task, we will try different encoding schemes for the inputs and apply possible classical post-processing on the quantum outputs to enhance the classification accuracy. In this tutorial, we stick to the TensorFlow backend and try to consistently use the **Keras interface** provided by tensorcircuit for quantum functions, where we can magically turn a quantum function into a Keras layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "86881b8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "from sklearn.decomposition import PCA\n",
    "import tensorflow as tf\n",
    "import tensorcircuit as tc\n",
    "\n",
    "K = tc.set_backend(\"tensorflow\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f92bc6f",
   "metadata": {},
   "source": [
    "## Dataset and Pre-processing\n",
    "\n",
    "We first load the fashion-mnist dataset and differentiation between T-shirt (0) and Trouser (1)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "81dcbf19",
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = tc.templates.dataset.mnist_pair_data(\n",
    "    0, 1, loader=tf.keras.datasets.fashion_mnist\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e4302f71",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((12000, 28, 28, 1), (12000,), (2000, 28, 28, 1), (2000,))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape, y_train.shape, x_test.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8a862a00",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f9147029610>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(x_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3b6115b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f91473b6c10>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(x_train[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2142169a",
   "metadata": {},
   "source": [
    "## Amplitude Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1cfd2225",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = tf.image.pad_to_bounding_box(x_train, 2, 2, 32, 32)\n",
    "x_test = tf.image.pad_to_bounding_box(x_test, 2, 2, 32, 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "09967af1",
   "metadata": {},
   "outputs": [],
   "source": [
    "batched_ae = K.vmap(tc.templates.dataset.amplitude_encoding, vectorized_argnums=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "92c8deec",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_q = batched_ae(x_train, 10)\n",
    "x_test_q = batched_ae(x_test, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dbadd88f",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 10\n",
    "blocks = 3\n",
    "\n",
    "\n",
    "def qml(x, weights):\n",
    "    c = tc.Circuit(n, inputs=x)\n",
    "    for j in range(blocks):\n",
    "        for i in range(n):\n",
    "            c.rx(i, theta=weights[j, i, 0])\n",
    "            c.rz(i, theta=weights[j, i, 1])\n",
    "        for i in range(n - 1):\n",
    "            c.exp1(i, i + 1, theta=weights[j, i, 2], unitary=tc.gates._zz_matrix)\n",
    "    outputs = K.stack(\n",
    "        [K.real(c.expectation([tc.gates.z(), [i]])) for i in range(n)]\n",
    "        + [K.real(c.expectation([tc.gates.x(), [i]])) for i in range(n)]\n",
    "    )\n",
    "    outputs = K.reshape(outputs, [-1])\n",
    "    return K.sigmoid(K.sum(outputs))\n",
    "\n",
    "\n",
    "qml_layer = tc.keras.QuantumLayer(qml, weights_shape=[blocks, n, 3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7502bc53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "75/75 [==============================] - 85s 559ms/step - loss: 0.6217 - binary_accuracy: 0.7667 - val_loss: 0.3990 - val_binary_accuracy: 0.9620\n",
      "Epoch 2/3\n",
      "75/75 [==============================] - 14s 185ms/step - loss: 0.3701 - binary_accuracy: 0.9571 - val_loss: 0.3421 - val_binary_accuracy: 0.9507\n",
      "Epoch 3/3\n",
      "75/75 [==============================] - 14s 185ms/step - loss: 0.3252 - binary_accuracy: 0.9542 - val_loss: 0.3030 - val_binary_accuracy: 0.9540\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f9147416e50>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = tf.keras.Sequential([qml_layer])\n",
    "model.compile(\n",
    "    loss=tf.keras.losses.BinaryCrossentropy(),\n",
    "    optimizer=tf.keras.optimizers.Adam(0.01),\n",
    "    metrics=[tf.keras.metrics.BinaryAccuracy()],\n",
    ")\n",
    "\n",
    "model.fit(x_train_q, y_train, batch_size=32, epochs=3, validation_split=0.8)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbb1becb",
   "metadata": {},
   "source": [
    "## Classical Post-processing\n",
    "\n",
    "We attached one Linear layer after the quantum outputs to enhance the capacity of the machine learning model as a quantum-neural hybrid machine learning approach."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5fa7ea38",
   "metadata": {},
   "outputs": [],
   "source": [
    "def qml(x, weights):\n",
    "    c = tc.Circuit(n, inputs=x)\n",
    "    for j in range(blocks):\n",
    "        for i in range(n):\n",
    "            c.rx(i, theta=weights[j, i, 0])\n",
    "            c.rz(i, theta=weights[j, i, 1])\n",
    "        for i in range(n - 1):\n",
    "            c.exp1(i, i + 1, theta=weights[j, i, 2], unitary=tc.gates._zz_matrix)\n",
    "    outputs = K.stack(\n",
    "        [K.real(c.expectation([tc.gates.z(), [i]])) for i in range(n)]\n",
    "        + [K.real(c.expectation([tc.gates.x(), [i]])) for i in range(n)]\n",
    "    )\n",
    "    outputs = K.reshape(outputs, [-1])\n",
    "    return outputs\n",
    "\n",
    "\n",
    "qml_layer = tc.keras.QuantumLayer(qml, weights_shape=[blocks, n, 3])\n",
    "\n",
    "inputs = tf.keras.Input(shape=(2 ** n), dtype=tf.complex64)\n",
    "measurements = qml_layer(inputs)\n",
    "output = tf.keras.layers.Dense(1, activation=\"sigmoid\")(measurements)\n",
    "model = tf.keras.Model(inputs=inputs, outputs=output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2b2133a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "75/75 [==============================] - 71s 508ms/step - loss: 0.5140 - binary_accuracy: 0.8841 - val_loss: 0.3617 - val_binary_accuracy: 0.9521\n",
      "Epoch 2/3\n",
      "75/75 [==============================] - 14s 182ms/step - loss: 0.2803 - binary_accuracy: 0.9421 - val_loss: 0.2093 - val_binary_accuracy: 0.9506\n",
      "Epoch 3/3\n",
      "75/75 [==============================] - 15s 200ms/step - loss: 0.2057 - binary_accuracy: 0.9437 - val_loss: 0.1795 - val_binary_accuracy: 0.9483\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f913d4ee520>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(\n",
    "    loss=tf.keras.losses.BinaryCrossentropy(),\n",
    "    optimizer=tf.keras.optimizers.Adam(0.01),\n",
    "    metrics=[tf.keras.metrics.BinaryAccuracy()],\n",
    ")\n",
    "\n",
    "model.fit(x_train_q, y_train, batch_size=32, epochs=3, validation_split=0.8)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb594290",
   "metadata": {},
   "source": [
    "## PCA Embedding\n",
    "\n",
    "Amplitude encoding is difficult to implement on real quantum hardware, we here instead consider another way for data input, where only a single qubit rotation is involved. To compress the input data such that it can fit into a small circuit, PCA dimension reduction is required."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6165ded0",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_r = PCA(10).fit_transform(x_train.numpy().reshape([-1, 32 * 32]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "db7352e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12000, 10)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train_r.shape  # we now has 10-d vector compression for each figure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c47a8b04",
   "metadata": {},
   "outputs": [],
   "source": [
    "def qml(x, weights):\n",
    "    c = tc.Circuit(n)\n",
    "    for i in range(10):\n",
    "        c.rx(i, theta=x[i])  # loading the data\n",
    "    for j in range(blocks):\n",
    "        for i in range(n):\n",
    "            c.rx(i, theta=weights[j, i, 0])\n",
    "            c.rz(i, theta=weights[j, i, 1])\n",
    "        for i in range(n - 1):\n",
    "            c.exp1(i, i + 1, theta=weights[j, i, 2], unitary=tc.gates._zz_matrix)\n",
    "    outputs = K.stack(\n",
    "        [K.real(c.expectation([tc.gates.z(), [i]])) for i in range(n)]\n",
    "        + [K.real(c.expectation([tc.gates.x(), [i]])) for i in range(n)]\n",
    "    )\n",
    "    outputs = K.reshape(outputs, [-1])\n",
    "    return K.sigmoid(K.sum(outputs))\n",
    "\n",
    "\n",
    "qml_layer = tc.keras.QuantumLayer(qml, weights_shape=[blocks, n, 3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ea292acf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "75/75 [==============================] - 71s 447ms/step - loss: 0.7993 - binary_accuracy: 0.6996 - val_loss: 0.3026 - val_binary_accuracy: 0.8829\n",
      "Epoch 2/3\n",
      "75/75 [==============================] - 6s 80ms/step - loss: 0.2745 - binary_accuracy: 0.8983 - val_loss: 0.2559 - val_binary_accuracy: 0.9087\n",
      "Epoch 3/3\n",
      "75/75 [==============================] - 6s 83ms/step - loss: 0.2513 - binary_accuracy: 0.9167 - val_loss: 0.2385 - val_binary_accuracy: 0.9187\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f91204f1430>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = tf.keras.Sequential([qml_layer])\n",
    "model.compile(\n",
    "    loss=tf.keras.losses.BinaryCrossentropy(),\n",
    "    optimizer=tf.keras.optimizers.Adam(0.01),\n",
    "    metrics=[tf.keras.metrics.BinaryAccuracy()],\n",
    ")\n",
    "\n",
    "model.fit(x_train_r, y_train, batch_size=32, epochs=3, validation_split=0.8)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c07a572",
   "metadata": {},
   "source": [
    "## Data Re-uploading\n",
    "\n",
    "By loading the PCA embedding data multiple times in the VQA, we may further increase the accuracy of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7cf9971b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def qml(x, weights):\n",
    "    c = tc.Circuit(n)\n",
    "    for j in range(blocks):\n",
    "        for i in range(10):\n",
    "            c.ry(i, theta=x[i])  # loading the data repetitively\n",
    "        for i in range(n):\n",
    "            c.rx(i, theta=weights[j, i, 0])\n",
    "            c.rz(i, theta=weights[j, i, 1])\n",
    "        for i in range(n - 1):\n",
    "            c.exp1(i, i + 1, theta=weights[j, i, 2], unitary=tc.gates._zz_matrix)\n",
    "    outputs = K.stack(\n",
    "        [K.real(c.expectation([tc.gates.z(), [i]])) for i in range(n)]\n",
    "        + [K.real(c.expectation([tc.gates.x(), [i]])) for i in range(n)]\n",
    "    )\n",
    "    outputs = K.reshape(outputs, [-1])\n",
    "    return K.sigmoid(K.sum(outputs))\n",
    "\n",
    "\n",
    "qml_layer = tc.keras.QuantumLayer(qml, weights_shape=[blocks, n, 3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9c974f4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "75/75 [==============================] - 20s 146ms/step - loss: 0.2506 - binary_accuracy: 0.9070 - val_loss: 0.2271 - val_binary_accuracy: 0.9177\n",
      "Epoch 2/3\n",
      "75/75 [==============================] - 7s 95ms/step - loss: 0.2191 - binary_accuracy: 0.9246 - val_loss: 0.2071 - val_binary_accuracy: 0.9287\n",
      "Epoch 3/3\n",
      "75/75 [==============================] - 7s 95ms/step - loss: 0.2049 - binary_accuracy: 0.9287 - val_loss: 0.2016 - val_binary_accuracy: 0.9305\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f90a813b460>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = tf.keras.Sequential([qml_layer])\n",
    "model.compile(\n",
    "    loss=tf.keras.losses.BinaryCrossentropy(),\n",
    "    optimizer=tf.keras.optimizers.Adam(0.01),\n",
    "    metrics=[tf.keras.metrics.BinaryAccuracy()],\n",
    ")\n",
    "\n",
    "model.fit(x_train_r, y_train, batch_size=32, epochs=3, validation_split=0.8)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
